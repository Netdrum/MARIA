{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1W3DhIUKfCQleDeoKsUvddUfAxmg6_e2w",
      "authorship_tag": "ABX9TyPOFGTCHgXAcLs35+1hTqqT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Netdrum/MARIA/blob/main/HF_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "!pip install huggingface_hub"
      ],
      "metadata": {
        "id": "pKNCZ7DW0Kqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import datasets\n",
        "import json\n",
        "import os"
      ],
      "metadata": {
        "id": "q-I6lWrZzQzc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "dsHq__tY3PSe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the dataset name and path\n",
        "dataset_name = \"IRCG_VHF\"  # Replace with your desired dataset name\n",
        "dataset_path = \"/content/drive/MyDrive/Dataset\"  # Replace with the path to your dataset\n",
        "\n",
        "def load_dataset(dataset_path):\n",
        "  \"\"\"Loads the dataset from the specified path.\n",
        "\n",
        "  Args:\n",
        "    dataset_path: Path to the dataset directory.\n",
        "\n",
        "  Returns:\n",
        "    A Hugging Face dataset.\n",
        "  \"\"\""
      ],
      "metadata": {
        "id": "2gMyJGqJ5HhC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# in this cell added in code to split the dataset into train and test splite and push to hf\n",
        "\n",
        "from datasets import load_dataset, Audio, Features, Value\n",
        "import json\n",
        "import os\n",
        "\n",
        "# Define the data directory\n",
        "data_dir = \"/content/drive/MyDrive/Dataset\"\n",
        "\n",
        "# Define the dataset features\n",
        "features = Features({\n",
        "    \"file_path\": Value(\"string\"),\n",
        "    \"duration\": Value(\"float32\"),\n",
        "    \"sample_rate\": Value(\"int32\"),\n",
        "    \"length\": Value(\"int32\"),\n",
        "    \"frame_rate\": Value(\"int32\"),\n",
        "    \"audio\": Audio(sampling_rate=16000),\n",
        "    \"transcription\": Value(\"string\")\n",
        "})\n",
        "\n",
        "# Load the dataset, extracting metadata from JSON files\n",
        "def extract_metadata(example):\n",
        "    # Assuming JSON files are named similarly to audio files with a .json extension:\n",
        "    json_file_path = example[\"file_path\"]  # Get the JSON file path\n",
        "\n",
        "    # Prepend the data directory to the JSON file path\n",
        "    json_file_path = os.path.join(data_dir, json_file_path)\n",
        "\n",
        "    # Add .json extension if it's missing\n",
        "    if not json_file_path.lower().endswith(\".json\"):\n",
        "        json_file_path += \".json\"\n",
        "\n",
        "    # Check if the JSON file exists\n",
        "    if not os.path.exists(json_file_path):\n",
        "        print(f\"Warning: JSON file not found: {json_file_path}\")\n",
        "        return example  # Skip this example if JSON file is not found\n",
        "\n",
        "    try:\n",
        "        # Open the JSON file with error handling and encoding specified\n",
        "        with open(json_file_path, 'r', encoding='latin-1') as f:\n",
        "            metadata = json.load(f)\n",
        "            example[\"duration\"] = metadata[\"duration\"]\n",
        "            example[\"sample_rate\"] = metadata[\"sample_rate\"]\n",
        "            example[\"length\"] = metadata[\"length\"]\n",
        "            example[\"frame_rate\"] = metadata[\"frame_rate\"]\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"Error decoding JSON in file: {json_file_path}\")\n",
        "        print(f\"Error message: {e}\")\n",
        "        return example  # Skip this example if JSON decoding fails\n",
        "\n",
        "    # Construct the audio file path based on the JSON file path\n",
        "    audio_file_path = json_file_path.replace(\".json\", \".wav\")  # Change .json to .wav\n",
        "\n",
        "    # Update the \"audio\" field with the path to the audio file\n",
        "    example[\"audio\"] = {\"path\": audio_file_path}\n",
        "\n",
        "    return example\n",
        "\n",
        "dataset = load_dataset(\"json\", data_files={\"train\": f\"{data_dir}/*.json\"}, features=features)\n",
        "dataset = dataset.map(extract_metadata)\n",
        "\n",
        "# Split the dataset into train and test\n",
        "train_testvalid_dataset = dataset[\"train\"].train_test_split(test_size=0.2, seed=42)\n",
        "\n",
        "# Extract train and test datasets\n",
        "train_dataset = train_testvalid_dataset[\"train\"]\n",
        "test_dataset = train_testvalid_dataset[\"test\"]\n",
        "\n",
        "# Push the datasets to the Hugging Face Hub\n",
        "train_dataset.push_to_hub(\"IRCG_VHF\", split=\"train\")\n",
        "test_dataset.push_to_hub(\"IRCG_VHF\", split=\"test\")"
      ],
      "metadata": {
        "id": "UM1QFPbDhzLq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}